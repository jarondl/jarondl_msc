%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%  pta notes
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[onecolumn,fleqn,longbibliography]{revtex4}

% fonts
\usepackage{latexsym}
\usepackage{amsmath} 
\usepackage{amssymb} 
\usepackage{bm}
\usepackage{wasysym}

\usepackage{graphicx}

\usepackage{color}
% extra by jarondl

\usepackage{array}
\usepackage{float}%unfloats
%\usepackage{multicol}
\usepackage[caption=false]{subfig} %subcaption is not compat with revtex
\usepackage[pdftitle={PTA},bookmarks]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% NEW 
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\varphiJ}{\bm{\varphi}}
\newcommand{\thetaJ}{\bm{\theta}}
%\renewcommand{\includegraphics}[2][0]{FIGURE}
\newcommand{\rmrk}[1]{\textcolor{red}{#1}}
\newcommand{\Eq}[1]{\textcolor{blue}{Eq.\!\!~(\ref{#1})}} 
\newcommand{\Fig}[1]{\textcolor{blue}{Fig.}\!\!~\ref{#1}}

% math symbols I
\newcommand{\sinc}{\mbox{sinc}}
\newcommand{\const}{\mbox{const}}
\newcommand{\trc}{\mbox{trace}}
\newcommand{\intt}{\int\!\!\!\!\int }
\newcommand{\ointt}{\int\!\!\!\!\int\!\!\!\!\!\circ\ }
\newcommand{\ar}{\mathsf r}
\newcommand{\im}{\mbox{Im}}
\newcommand{\re}{\mbox{Re}}

% math symbols II
\newcommand{\eexp}{\mbox{e}^}
\newcommand{\bra}{\left\langle}
\newcommand{\ket}{\right\rangle}

% Mass symbol
\newcommand{\mass}{\mathsf{m}} 
\newcommand{\rdisc}{\epsilon} 

% more math commands
\newcommand{\tbox}[1]{\mbox{\tiny #1}}
\newcommand{\bmsf}[1]{\bm{\mathsf{#1}}} 
\newcommand{\amatrix}[1]{\begin{matrix} #1 \end{matrix}} 
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}

% equations
\newcommand{\mylabel}[1]{\label{#1}} 
\newcommand{\beq}{\begin{eqnarray}}
\newcommand{\eeq}{\end{eqnarray}} 
\newcommand{\be}[1]{\begin{eqnarray}\ifthenelse{#1=-1}{\nonumber}{\ifthenelse{#1=0}{}{\mylabel{e#1}}}}
\newcommand{\ee}{\end{eqnarray}} 

% arrangement
\newcommand{\hide}[1]{}
\newcommand{\drawline}{\begin{picture}(500,1)\line(1,0){500}\end{picture}}
\newcommand{\bitem}{$\bullet$ \ \ \ }
\newcommand{\Cn}[1]{\begin{center} #1 \end{center}}
\newcommand{\mpg}[2][1.0\hsize]{\begin{minipage}[b]{#1}{#2}\end{minipage}}
\newcommand{\mpgt}[2][1.0\hsize]{\begin{minipage}[t]{#1}{#2}\end{minipage}}


%footnotemark:
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Sections
\newcommand{\sect}[1]
{
\addtocounter{section}{1} 
\setcounter{subsection}{0}
\ \\ 
\pdfbookmark[2]{\thesection. \ #1}{sect.\thesection}
{\Large\bf $=\!=\!=\!=\!=\!=\;$ [{\thesection}] \ #1}  
\nopagebreak
}


% subections
\newcommand{\subsect}[1]
{
\addtocounter{subsection}{1} 
\ \\ 
\pdfbookmark[2]{\ \ \ \ \thesection.\thesubsection. \ #1}{subsect.\thesection.\thesubsection}
{\bf $=\!=\!=\!=\!=\!=\;$ [\thesection.\thesubsection] \ #1} 
\nopagebreak
}
%%% fix numbering to be arabic:
\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\arabic{subsection}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% extra commands by jarondl
%% 
\newcommand{\kket}[1]{\left| #1 \right\rangle }
\newcommand{\bbra}[1]{\left\langle #1 \right| }

\graphicspath{{figures/}}
\begin{document}

\title{PTA - Anderson}

\author{YdL}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
\sect{Introduction}

%%%%%%%%%%%%%%%
\sect{Model}

The model is a $1d$ chain, with constant hopping and random site energies.
In site representation, 
where $\kket{n}$ is site number $n$, the Hamiltonian is:
\begin{align}
    \mathcal{H} \ &= \ \sum_n^N \kket{n}\bbra{n} \varepsilon_n \ + \ \kket{n}\bbra{n+1}c \\
    c  \ &= \ 1 \\
    \varepsilon_n \ &\in \ \left[-\frac{W}{2} \ ,\  +\frac{W}{2} \right]
\end{align}
${c}$ is a constant that sets the energy scale, 
and $\varepsilon_n$ is a random variable 
\textbf{uniformly} distributed on the stated range. 
The free parameters are therefore ${W}$ and ${N}$.

%%%%%%%%%%%%%%%%%
\sect{Localization length}

The modes are localized, with localization length $\xi$. The more commonly used parameter is the corresponding Lyapunov exponent ${\gamma = \xi^{-1}}$. Strictly speaking, this is the $N\rightarrow\infty$ limit of $\gamma_N$. Anyway, the known result 
\cite{deych_single-parameter_2001,kramer_localization:_1993,markos_numerical_2006}
for this speccific model in the weak disorder limit is
\begin{align*}
    \gamma(E)  \ &= \ \frac{\left\langle \varepsilon^2\right\rangle}{2\cdot\left(4\cdot c^2 -E^2\right)} \ = \ \frac{W^2}{24\cdot\left(4\cdot c^2 -E^2\right)}
\end{align*}


%%%%%%%%%%%%%%%%%%%
\sect{Calculating conductivity}

%%%%%%%%%%%%%%%%%%%
\subsect{S - matrix}

In this formalism, we attach one tight-binding lead to site $1$, and another to site $N$, with coupling $\Gamma$. 
Solving for the leads, we end with a transmission matrix :
\begin{align}
T \  &= \  \left\langle 1 \right |\frac{\Gamma v}{E-\mathcal{H}_{0} -(\Gamma/2)(E-iv)Q^\dagger Q}\left|N\right\rangle\\
Q^\dagger Q \ &=\ \kket{1}\bbra{1} + \kket{N}\bbra{N} \\
g(E,v)  \ &= \  T^2 
\end{align}
With ${E}$ and ${v}$ being the energy and velocity of
the lead modes. From now on we assume ${\Gamma =1 }$. In this case the energy and velocity are:
\begin{align}
    E \ = \ -2c\cdot\cos(k) 
    \qquad v  \ = \ 2c\cdot\sin(k) 
\end{align}
\rmrk{This $c$ is actually of the leads right? and 
$k$ is quantized by the lead length?}

The numerical calculation of this transmission is done
by built-in numerical inversion of the matrix.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsect{The diagonal approximation}

The diagonal approximation involves two steps. The
first is using only the diagonal parts of $Q^\dagger Q$ in the basis that diagonalizes $\mathcal{H}_0$. 
The second step is to sum squared absolute values instead
of first summing up and then squaring.

Denoting the $\alpha$ eigenmode of $\mathcal{H}_0$ by $\psi^\alpha_n$, with energy $\lambda_\alpha$, the expression we calculate is:
\begin{align}
g_{DA} \ = \    \sum_\alpha \left| \frac{\psi_1^\alpha\psi_N^\alpha \Gamma v}{E-\lambda_\alpha - \frac{\Gamma}{2}(E-iv)\cdot\left(|\psi_1^\alpha|^2+|\psi_N^\alpha|^2\right)}  \right|^2
\end{align}

Some approximation for this expression gives us:
\begin{align}
    g_a \ &\equiv \ \left[ \Gamma N \left(2 \frac{|\psi_1|^2|\psi_N|^2}{|\psi_1|^2 + |\psi_N|^2} \right)\right]  \quad = 
    \quad  \left[ \Gamma N \left( \frac{1}{\frac{1}{2|\psi_1|^2} + \frac{1}{2|\psi_N|^2}} \right)\right] \\
    g_{DA}(E) \ &= \ \left\langle g_a \right\rangle_E
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsect{Heat conduction}

\begin{align}
    g_h \ &= \ \left\langle g_a \right\rangle
\end{align}
This fits with the idea the the heat 
conduction is an average over the electric conduction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsect{Expected result for ${g}$}

It is known that ${g}$ is not self-averaging, while
${\ln(g)}$ is. The known result is:
\begin{align}
    \langle \ln(g)\rangle \ &= \ -2\gamma N\\
    \textrm{var}(\ln(g)) \ &= \ 2\gamma N
\end{align}

Regarding ${g}$ itself it is claimed \cite{kramer_localization:_1993} that
\begin{align}
    \ln(\langle  g\rangle) \ &= \  \frac{1}{4}\langle \ln(g)\rangle = -\frac{1}{2}\gamma N
\end{align}
However if ${g}$ is log-normal, it follows that:
\begin{align}
    \langle g\rangle \ &= \ e^{\langle \ln(g)\rangle + \frac{1}{2}\textrm{var}(\ln(g))} = e^{-2\gamma N +\gamma N} \\
    \ln(\langle  g\rangle) \ &= \ -\gamma N
\end{align}
\rmrk{I do not know the reason for this discrepancy}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{Numerical results}

Here follows a set of figures, plotting ${\ln(g)}$  as a function of ${N}$ for several calculation methods. The difference between the figures is in ${W}$ and the range of ${N}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{${g}$ as a function of ${N}$ }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[H]
\includegraphics{{{pta_gamma_tall_wide_of_N_0.4}}}
\caption{${g}$ is caluclated using matrix inversion 
as described above. ${g_{DA}}$ is the diagonal approximation,
and ${g_H}$ is the heat conduction. Angled brackets denote 
averaging (in this case over ${40}$ realizations). Note the
differnce between regular average and log average. The vertical grey
line is for ${\gamma^{-1}}$.}
\end{figure}
%%%%%%%%%%%%%%%
\begin{figure}[H]
\includegraphics{{{pta_gamma_wide_of_N_1.0}}}
\end{figure}
\begin{figure}[H]
\includegraphics{{{pta_gamma_wide_of_N_2.0}}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\sect{dispersion of g}

As the previous section showed, it is hard to find a "sweet spot" where
the numerics and theory agree. On the theoretical view point,
we want on the one hand to be in the strong localization regime,
which means
\begin{align}
    \xi \ll N   \qquad \Leftrightarrow \qquad \gamma N \gg 1
\end{align}
On the other hand, the results assume
\begin{align} \\
W &\ll c =1\\
    \xi &\gg 1 \qquad \Leftrightarrow \qquad \gamma \ll 1
\end{align}
Which means we need to $N$ to be rather large.
On the numerical side, when matrix inversion, larger $N$ is
exponentially slower, as well as less accurate.

To check how the dispersion behaves for various configurations,
we plot histograms of ${g_h}$ and ${g}$. In all of the following plots,
the left is $g$ and the right is $g_h$. Above is log scale, and below regular. The solid black line is the expected gaussian form, the 
dashed is a fitted gaussian. The green line is $2\gamma N$, red is $\gamma N$. ${\#}$ is the number of realizations. The histograms are
normalized so that the sum is always ${1}$. The top three sets are with
$w=0.4$, but differing number of sites. The next two sets are with
$W=1.0$ and $W=2.0$, which is even larger than ${c}$, so perhaps 
not relevant.


\begin{figure}[H]
\includegraphics{{{pta_disperse_s_0.4}}}
\end{figure}
\begin{figure}[H]
\includegraphics{{{pta_disperse1600_s_0.4}}}
\end{figure}
\begin{figure}[H]
\includegraphics{{{pta_disperse2000_s_0.4}}}
\end{figure}
\begin{figure}[H]
\includegraphics{{{pta_disperse_s_1.0}}}
\end{figure}
\begin{figure}[H]
\includegraphics{{{pta_disperse_s_2.0}}}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{apsrev4-1}
\bibliography{../bibliography/jarondl,../bibliography/custom-longbib}


\end{document}
